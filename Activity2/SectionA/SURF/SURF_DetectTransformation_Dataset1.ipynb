{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SURF_DetectTransformation_Dataset1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM+kj8yRvf1CaWj8FWwFR7c"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "avFQH93hTUUW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-contrib-python==3.4.2.17\n",
        "import cv2 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mu8hDYhTqx8",
        "outputId": "92380457-b5d8-412e-8480-dd068eba7da9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opencv-contrib-python==3.4.2.17\n",
            "  Downloading opencv_contrib_python-3.4.2.17-cp37-cp37m-manylinux1_x86_64.whl (30.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 30.6 MB 71 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python==3.4.2.17) (1.21.6)\n",
            "Installing collected packages: opencv-contrib-python\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.1.2.30\n",
            "    Uninstalling opencv-contrib-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-contrib-python-4.1.2.30\n",
            "Successfully installed opencv-contrib-python-3.4.2.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create SURF object. \n",
        "surf = cv2.xfeatures2d.SURF_create()"
      ],
      "metadata": {
        "id": "49l9ZACJT0D7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queryImage_path = \"/content/Modelo.png\"\n",
        "trainImage_path = \"/content/t1.png\"\n",
        "\n",
        "queryImage = cv2.imread(queryImage_path, cv2.IMREAD_COLOR)\n",
        "trainImage = cv2.imread(trainImage_path, cv2.IMREAD_COLOR)"
      ],
      "metadata": {
        "id": "ACMO8Bl3UaEy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queryImage_keypoints = surf.detect(queryImage,None)\n",
        "trainImage_keypoints = surf.detect(trainImage, None)"
      ],
      "metadata": {
        "id": "sAJGrf9hUnyp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queryImage_keypoints, queryImage_descriptors = surf.compute(queryImage, queryImage_keypoints)\n",
        "trainImage_keypoints, trainImage_descriptors = surf.compute(trainImage, trainImage_keypoints)"
      ],
      "metadata": {
        "id": "ny39advfVNBU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bKSWUAT6nMVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
        "matches = bf.match(queryImage_descriptors, trainImage_descriptors)"
      ],
      "metadata": {
        "id": "hHwzT-yxVX1g"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of Keypoints in query Image: \", len(queryImage_keypoints))\n",
        "print(\"Number of Keypoints in training Image: \", len(trainImage_keypoints))\n",
        "print(\"Number of Matching Keypoints Between The Training and Query Images: \", len(matches))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhtaqlhJc7nJ",
        "outputId": "4de9ace7-2f80-4b82-cbd5-38fb55d73509"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Keypoints in query Image:  1366\n",
            "Number of Keypoints in training Image:  1404\n",
            "Number of Matching Keypoints Between The Training and Query Images:  516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get three random match indices which are not the same\n",
        "match_index_a = random.randint(0, len(matches) - 1)\n",
        "match_index_b = random.randint(0, len(matches) - 1)\n",
        "match_index_c = random.randint(0, len(matches) - 1)"
      ],
      "metadata": {
        "id": "dKGZ_5s3Vcsp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get Keypoints from match indices\n",
        "# queryImage- keypoints\n",
        "queryImage_keypoint_a = queryImage_keypoints[matches[match_index_a].queryIdx]\n",
        "queryImage_keypoint_b = queryImage_keypoints[matches[match_index_b].queryIdx]\n",
        "queryImage_keypoint_c = queryImage_keypoints[matches[match_index_c].queryIdx]\n",
        "\n",
        "# trainImage-keypoints\n",
        "trainImage_keypoint_a = trainImage_keypoints[matches[match_index_a].trainIdx]\n",
        "trainImage_keypoint_b = trainImage_keypoints[matches[match_index_b].trainIdx]\n",
        "trainImage_keypoint_c = trainImage_keypoints[matches[match_index_c].trainIdx]"
      ],
      "metadata": {
        "id": "hXg_aLbOVmpp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get affine transformation matrix from these 6 keypoints\n",
        "trainImage_points = np.float32([[trainImage_keypoint_a.pt[0], trainImage_keypoint_a.pt[1]],\n",
        "                                [trainImage_keypoint_b.pt[0], trainImage_keypoint_b.pt[1]],\n",
        "                                [trainImage_keypoint_c.pt[0], trainImage_keypoint_c.pt[1]]])\n",
        "\n",
        "queryImage_points = np.float32([[queryImage_keypoint_a.pt[0], queryImage_keypoint_a.pt[1]],\n",
        "                                [queryImage_keypoint_b.pt[0], queryImage_keypoint_b.pt[1]],\n",
        "                                [queryImage_keypoint_c.pt[0], queryImage_keypoint_c.pt[1]]])\n"
      ],
      "metadata": {
        "id": "6wwVCc9LVzcO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queryImage_points"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRIxd-pxWOMe",
        "outputId": "f645a320-d237-4d0f-b36d-c187bae31f00"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[160.25482 , 238.13702 ],\n",
              "       [329.6805  , 116.232376],\n",
              "       [173.82631 , 146.08896 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainImage_points"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRlkIwVCWSJn",
        "outputId": "d4d4e075-422e-487e-fccb-d14337c9b233"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[299.58804 ,  59.626835],\n",
              "       [139.36641 , 137.42348 ],\n",
              "       [250.63588 ,  82.67121 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get transformation matrix for current points\n",
        "currentMatrix = cv2.getAffineTransform(queryImage_points, trainImage_points)"
      ],
      "metadata": {
        "id": "JnsbF8QuWY3G"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Affine transformation')\n",
        "currentMatrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zjq6Mo-BWaPu",
        "outputId": "6d05b7ae-6622-4733-8546-570047334d2f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Affine transformation\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-6.29845133e-01,  4.38947069e-01,  2.95994214e+02],\n",
              "       [ 3.12162070e-01, -2.04326650e-01,  5.82590982e+01]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}